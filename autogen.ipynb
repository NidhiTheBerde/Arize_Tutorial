{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial : Building a Multi-Agent Chat System with Azure OpenAI, Autogen and Tracing using Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction : In this tutorial, we'll guide you through building a multi-agent chat system using Azure OpenAI deployments. The example in this tutorial is a customer query resolver agent. The system will utilize multiple AI Agents, each with a specific role, to colaboratively come up with a solution to user query. You'll see how to co-ordinate these agents in a RoundRobin Fashion, trace their interactions with Phoenic and add human annotations for debugging and optimization. The applications of multi-agent systems are very diverse. The Agents are capable of handing both TextMessage or MultiModalMessage. Autogen AgentChat provides a set of preset Agents, each with variations on how an agent might respond to messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer <a href = https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html>Autogen</a> Documentation for more details about AgentChat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prequisites : Python, Access to OpenAI models. Other dependencies are listed in requirements.txt. \n",
    "Run pip install -r /path/to/requirements.txt to have all packages installed at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is a good practice to save all api keys, endpoints and other important details in an env file. \n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(\"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the Phoenix App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Arize_Tutorial/my_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n",
      "üì∫ Opening a view to the Phoenix app. The app is running at http://localhost:6006/\n",
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch Phoenix\n",
    "import os\n",
    "if \"PHOENIX_API_KEY\" in os.environ:\n",
    "    os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n",
    "\n",
    "else:\n",
    "    import phoenix as px\n",
    "\n",
    "    px.launch_app().view()\n",
    "\n",
    "# Connect to Phoenix\n",
    "from phoenix.otel import register\n",
    "tracer_provider = register()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instrument OpenAI for tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, agents need access to LLM model services such as OpenAI, Azure OpenAI, or local models. Since there are many different providers with different APIs, autogen-core implements a protocol for model clients and autogen-ext implements a set of model clients for popular model services. AgentChat can use these model clients to interact with model services.\n",
    "\n",
    "To use the Azure OpenAI, you need to provide your deployment id, Azure Cognitive Services endpoint, api version, and model capabilities. For authentication, you can either provide an API key or an Azure Active Directory (AAD) token credential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Set up your Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    " \n",
    "\n",
    "#Set up Azure OpenAI Configuration using environment variables\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "DEPLOYMENT_NAME = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"API_VERSION\")\n",
    "\n",
    " \n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"model_name\",\n",
    "    model=\"model_name\",\n",
    "    api_version=\"your_model_version\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    temperature=0.2,\n",
    "    max_tokens=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Define Agent Functions\n",
    "Each Agent is initialized using the AssistantAgent class from Autogen. It's up to the developer to decide the system message according to their needs\n",
    "Here I have used three agents - Classifier, Resolver and Feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination # type: ignore\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat \n",
    "\n",
    "classifier_agent = AssistantAgent(\n",
    "\n",
    "    name=\"classifier\",\n",
    "    model_client =az_model_client,\n",
    "\n",
    "    system_message=(\"You are a classifier that determines the category og a customer query\"\n",
    "                    \"The categories are Billing, Technical Support, Shipping or General Inquiry\"\n",
    "                    \"Respond only with categoy name\")\n",
    ")\n",
    "\n",
    "\n",
    "problem_solver_agent = AssistantAgent(\n",
    "\n",
    "    name=\"problem_solver\",\n",
    "\n",
    "    model_client = az_model_client,\n",
    "\n",
    "    system_message=(\"You are a resolver that answers customer queries based on their category.\"\n",
    "                    \"You will receive the category and query, and you must provide a resolution\"\n",
    "                    \"Be concise, clear, and empatheic in your response\"\n",
    "                    \"Try to limit the answers in 5 lines\")\n",
    "\n",
    ")\n",
    "\n",
    "feedbackagent = AssistantAgent(\n",
    "    name = \"feedback_agent\",\n",
    "     model_client=az_model_client,\n",
    "    system_message=(\n",
    "        \"You analyse customer interactions for sentiments and suggest improvements\"\n",
    "        \"If the sentiment is negative, identify and propose better response\"\n",
    "        \"If all looks good respond with TERMINATE\"\n",
    "    )\n",
    ")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Now we set up a team using the RoundRobinGroupChat configuration. This configuration allows multiple agents to work together in a round-robin fashion, where each agent takes turns responding while maintaining a shared context.\n",
    "\n",
    "The AssistantAgent is responsible for generating responses based on the given input. Additionally, we will set a TextMentionTermination condition that stops the team when a specific word is detected in any of the agent's responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination =TextMentionTermination(\"TERMINATE\")\n",
    "group_chat1 = RoundRobinGroupChat(\n",
    "    [classifier_agent, problem_solver_agent, feedbackagent], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import TraceDataset\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who do i contact for broken screen?\"\n",
    "await Console(group_chat1.run_stream(task=query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_chat2 = RoundRobinGroupChat(\n",
    "    [classifier_agent, problem_solver_agent, feedbackagent], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"My payment isnt going through on your app\"\n",
    "await Console(group_chat2.run_stream(task=f\"Query: {query1}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"I cant log into my account\"\n",
    "await Console(group_chat2.run_stream(task=f\"Query: {query2}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 : Open the phoenix url that opened in your localhost, you will now see the traces for all the queries that we ran.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"img7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 : Adding Human Annotations\n",
    "\n",
    "In order to improve your LLM application iteratively, it's vital to collect feedback as well as to establish an evaluation pipeline so that you can monitor your application. In Phoenix we capture this type of feedback in the form of annotations.\n",
    "\n",
    "Phoenix gives you the ability to annotate traces with feedback from two sources: LLM in the form of evaluations and HUMAN in the form of human annotations. Phoenix's annotation model is simple yet powerful - given an entity such as a span that is collected, you can assign a label and/or a score to that entity. \n",
    "\n",
    "Human Annotations act as an extra layer of quality assurance which can be used for sharing insights within a team, curating datasets of good/bad examples, and even in training an LLM judge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply click on the Trace and then click on 'Annotate'. Next give a suitable name to your annotation, provide label and a score for your reference. Refer the images below or visit this <a href=https://docs.arize.com/phoenix/tracing/llm-traces/how-to-annotate-traces>link</a> for a quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"img2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"img1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done they look like this\n",
    "\n",
    "<img src = \"img3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add more than one annotation for each trace\n",
    "\n",
    "<img src=\"img6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also Filter your traces based on the annotations, or any other filter conditions to easliy view your traces. Click on the '+' in the search bar and add the filter\n",
    "\n",
    "<img src = \"img5.png\">\n",
    "<img src = \"img4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 : Save and Load Traces as per use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traces = px.Client().get_trace_dataset().save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.session.session.ThreadSession at 0x721cdaffb950>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.launch_app(trace=px.TraceDataset.load(my_traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
